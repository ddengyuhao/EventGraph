import os
import json
import glob
from torch.utils.data import Dataset

class LVBenchDataset(Dataset):
    def __init__(self, root_dir="/root/icml2026/dataset/LVBench/LVBench", split="test", max_samples=None):
        """
        LVBench æ•°æ®é›†åŠ è½½å™¨ (é€‚é…ç”¨æˆ·æˆªå›¾ç›®å½•ç»“æ„)
        Args:
            root_dir: LVBench é¡¹ç›®çš„æ ¹ç›®å½• (åŒ…å« data, scripts ç­‰æ–‡ä»¶å¤¹)
            max_samples: ä»…åŠ è½½å‰ N ä¸ªæ ·æœ¬ç”¨äºå¿«é€Ÿæµ‹è¯•
        """
        self.root_dir = root_dir
        self.samples = []
        
        print(f"ğŸ“‚ [LVBench] åˆå§‹åŒ–æ•°æ®é›†ï¼Œæ ¹ç›®å½•: {self.root_dir}")

        # ==================================================
        # 1. å¯»æ‰¾å…ƒæ•°æ®æ–‡ä»¶ (video_info.meta.jsonl)
        # æ ¹æ®æˆªå›¾ï¼Œå®ƒåº”è¯¥åœ¨ data/ ç›®å½•ä¸‹
        # ==================================================
        meta_search_paths = [
            os.path.join(self.root_dir, "data", "*.jsonl"),      # ä¼˜å…ˆæ‰¾ data/
            os.path.join(self.root_dir, "**", "*.jsonl")         # å¤‡ç”¨ï¼šé€’å½’æ‰¾
        ]
        
        meta_path = None
        for pattern in meta_search_paths:
            found = glob.glob(pattern, recursive=True)
            for f in found:
                if "meta" in os.path.basename(f): # ç¡®ä¿æ–‡ä»¶ååŒ…å« meta
                    meta_path = f
                    break
            if meta_path: break
        
        if not meta_path:
            raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° video_info.meta.jsonlï¼è¯·æ£€æŸ¥ {self.root_dir}/data ç›®å½•ã€‚")
            
        print(f"ğŸ“„ åŠ è½½å…ƒæ•°æ®: {meta_path}")

        # ==================================================
        # 2. å»ºç«‹æœ¬åœ°è§†é¢‘ç´¢å¼• (é€‚é… scripts/tmp å’Œ scripts/videos)
        # ==================================================
        print("ğŸ” æ‰«ææœ¬åœ°è§†é¢‘æ–‡ä»¶...")
        video_map = {}
        
        # å®šä¹‰æœç´¢è·¯å¾„ï¼Œæ ¹æ®ä½ çš„æˆªå›¾ï¼š
        # 1. scripts/tmp/*.mp4 (ä½ æ‰‹åŠ¨ä¸‹è½½æˆ–ç¼“å­˜çš„)
        # 2. scripts/videos/**/*.mp4 (video2dataset ä¸‹è½½çš„)
        video_search_patterns = [
            os.path.join(self.root_dir, "scripts", "tmp", "*.mp4"),
            os.path.join(self.root_dir, "scripts", "videos", "**", "*.mp4"),
            os.path.join(self.root_dir, "**", "*.mp4") # å…¨å±€é€’å½’å…œåº•
        ]
        
        found_videos_count = 0
        for pattern in video_search_patterns:
            files = glob.glob(pattern, recursive=True)
            for v_path in files:
                fname = os.path.basename(v_path)
                fid = os.path.splitext(fname)[0] # è·å–æ–‡ä»¶åä½œä¸º ID (ä¾‹å¦‚ 2sriHX3PbXw)
                
                # åªæœ‰å½“è¯¥ ID è¿˜æ²¡è¢«è®°å½•æ—¶æ‰æ·»åŠ  (é¿å…é‡å¤)
                if fid not in video_map:
                    video_map[fid] = v_path
                    found_videos_count += 1

        print(f"   ç¡¬ç›˜ä¸Šå…±æ‰¾åˆ° {found_videos_count} ä¸ªè§†é¢‘æ–‡ä»¶ã€‚")

        # ==================================================
        # 3. è§£æ JSONL å¹¶æ„å»ºæ ·æœ¬
        # ==================================================
        skipped_count = 0
        
        try:
            with open(meta_path, 'r', encoding='utf-8') as f:
                for line in f:
                    if not line.strip(): continue
                    
                    entry = json.loads(line)
                    video_id = entry.get('key', '') # LVBench ä½¿ç”¨ 'key' (YouTube ID)
                    
                    # å…³é”®æ­¥éª¤ï¼šæ£€æŸ¥è¯¥ ID æ˜¯å¦åœ¨æˆ‘ä»¬çš„è§†é¢‘æ–‡ä»¶åˆ—è¡¨ä¸­
                    if video_id in video_map:
                        video_path = video_map[video_id]
                    else:
                        # æ²¡ä¸‹è½½è§†é¢‘åˆ™è·³è¿‡
                        skipped_count += 1
                        continue 

                    # éå†è¯¥è§†é¢‘ä¸‹çš„æ‰€æœ‰é—®é¢˜ ('qa' å­—æ®µ)
                    for q_item in entry.get('qa', []):
                        question = q_item.get('question', '')
                        
                        # è§£æé€‰é¡¹ (LVBench é€šå¸¸æ˜¯ A,B,C,D)
                        options = []
                        # å°è¯•ä» option1...option4 å­—æ®µè¯»å–
                        for opt_key in ['option1', 'option2', 'option3', 'option4']:
                            if opt_key in q_item:
                                options.append(q_item[opt_key])
                        
                        # å¦‚æœä¸Šé¢çš„æ–¹å¼æ²¡è¯»åˆ°ï¼Œå°è¯•ç›´æ¥è¯»å–åˆ—è¡¨
                        if not options and 'options' in q_item:
                             options = q_item['options']

                        # å¤„ç†ç­”æ¡ˆ (0->A, 1->B ...)
                        answer_raw = q_item.get('answer', '')
                        if isinstance(answer_raw, int):
                            answer = chr(65 + answer_raw) 
                        else:
                            answer = str(answer_raw).upper()

                        # ä»»åŠ¡ç±»å‹
                        task_type = q_item.get('question_type', 'general')

                        self.samples.append({
                            "id": f"{video_id}_{len(self.samples)}",
                            "video_path": video_path,
                            "question": question,
                            "options": options,
                            "answer": answer,
                            "task_type": task_type
                        })

        except Exception as e:
            print(f"âŒ JSONL è¯»å–å¤±è´¥: {e}")

        # 4. æˆªå–å°æ ·æœ¬æµ‹è¯•
        if max_samples is not None and max_samples > 0:
            print(f"âœ‚ï¸ [Test Mode] æˆªå–å‰ {max_samples} ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•ã€‚")
            self.samples = self.samples[:max_samples]

        print(f"âœ… æ•°æ®é›†æ„å»ºå®Œæˆï¼")
        print(f"   - åŒ¹é…æˆåŠŸçš„è§†é¢‘æ•°: {len(set(s['video_path'] for s in self.samples))}")
        print(f"   - è·³è¿‡(æ— è§†é¢‘): {skipped_count} ä¸ªæ¡ç›®")
        print(f"   - æœ€ç»ˆé¢˜ç›®æ•°é‡: {len(self.samples)}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        return self.samples[idx]