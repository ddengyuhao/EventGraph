#!/usr/bin/env python3
"""
LLaVA-NeXT-Video-34B æ¨¡å‹å°è£…
åŸºäº test_llava_next_34b_hf.py çš„æœ€ä½³å®è·µ

å…³é”®é…ç½®ï¼š
- ä½¿ç”¨ LlavaNextVideoForConditionalGeneration
- FP16 å®Œæ•´ç²¾åº¦ï¼ˆä¸é‡åŒ–ï¼‰
- device_map="auto" å¤šå¡è‡ªåŠ¨åˆ†é…
- å»ºè®®è¾“å…¥ï¼š32å¸§ï¼ˆè®ºæ–‡æœ€ä½³å®è·µï¼‰
"""

import torch
from transformers import LlavaNextVideoProcessor, LlavaNextVideoForConditionalGeneration
from PIL import Image
import numpy as np
import re


class LLaVANext34BWrapper:
    def __init__(self, model_path="/root/hhq/models/LLaVA-NeXT-Video-34B-hf"):
        """
        åˆå§‹åŒ– LLaVA-NeXT-Video-34B æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹æƒé‡è·¯å¾„
        """
        print(f"[LLaVA-NeXT-34B] Loading model from {model_path}...")
        
        # åŠ è½½ Processor
        self.processor = LlavaNextVideoProcessor.from_pretrained(model_path)
        print(f"  âœ“ Processor loaded")
        
        # åŠ è½½æ¨¡å‹ï¼ˆFP16 å®Œæ•´ç²¾åº¦ï¼‰
        self.model = LlavaNextVideoForConditionalGeneration.from_pretrained(
            model_path,
            torch_dtype=torch.float16,  # FP16 å®Œæ•´ç²¾åº¦
            device_map="auto",  # è‡ªåŠ¨å¤šå¡åˆ†é…
            low_cpu_mem_usage=True
        )
        self.model.eval()
        print(f"  âœ“ Model loaded (FP16, device_map=auto)")
        
        # è·å–è®¾å¤‡
        self.device = next(self.model.parameters()).device
        print(f"  âœ“ Device: {self.device}")
        
        # æœ€ä½³å¸§æ•°é…ç½®
        self.recommended_frames = 32
        
    def generate(self, frames, question, options=None):
        """
        ä½¿ç”¨ LLaVA-NeXT-34B ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            frames: PIL Image åˆ—è¡¨ï¼Œé•¿åº¦ <= 32
            question: é—®é¢˜æ–‡æœ¬
            options: é€‰é¡¹åˆ—è¡¨ (å¯é€‰ï¼Œç”¨äºå¤šé€‰é¢˜)
        
        Returns:
            answer: ç”Ÿæˆçš„ç­”æ¡ˆæ–‡æœ¬ï¼ˆå¦‚æœæ˜¯å¤šé€‰é¢˜ï¼Œè¿”å› A/B/C/Dï¼‰
        """
        # æ£€æŸ¥å¸§æ•°
        num_frames = len(frames)
        if num_frames > self.recommended_frames:
            print(f"âš ï¸  Warning: {num_frames} frames provided, recommended max is {self.recommended_frames}")
        
        # æ„é€  promptï¼ˆLLaVA-NeXT æ ¼å¼ï¼‰
        if options:
            # å¤šé€‰é¢˜æ ¼å¼
            options_text = "\n".join([f"{chr(65+i)}. {opt}" for i, opt in enumerate(options)])
            prompt = f"USER: <video>\n{question}\n{options_text}\nAnswer with the option's letter from the given choices directly.\nASSISTANT:"
        else:
            # å¼€æ”¾å¼é—®é¢˜
            prompt = f"USER: <video>\n{question}\nASSISTANT:"
        
        # è½¬æ¢ PIL å›¾åƒåˆ—è¡¨ä¸º numpy array
        # shape: (num_frames, H, W, 3)
        video_array = np.stack([np.array(f) for f in frames])
        
        # ä½¿ç”¨ processor å¤„ç†
        inputs = self.processor(
            text=prompt,
            videos=video_array,
            padding=True,
            return_tensors="pt"
        )
        
        # ç§»åŠ¨åˆ° GPU
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # pixel_values éœ€è¦è½¬ä¸º float16 ä»¥åŒ¹é…æ¨¡å‹
        if 'pixel_values_videos' in inputs:
            inputs['pixel_values_videos'] = inputs['pixel_values_videos'].to(torch.float16)
        
        # ç”Ÿæˆç­”æ¡ˆ
        with torch.inference_mode():
            output_ids = self.model.generate(
                **inputs,
                max_new_tokens=100,
                do_sample=False,
                temperature=None,
                top_p=None
            )
        
        # è§£ç 
        output_text = self.processor.batch_decode(output_ids, skip_special_tokens=True)[0]
        
        # æ¸…ç†è¾“å‡ºï¼ˆç§»é™¤ prompt éƒ¨åˆ†ï¼‰
        # LLaVA-NeXT è¾“å‡ºæ ¼å¼ï¼šUSER: ... ASSISTANT: <answer>
        if "ASSISTANT:" in output_text:
            output_text = output_text.split("ASSISTANT:")[-1].strip()
        
        # å¦‚æœæ˜¯å¤šé€‰é¢˜ï¼Œæå–é€‰é¡¹å­—æ¯
        if options:
            answer = self._extract_option(output_text, len(options))
        else:
            answer = output_text
        
        return answer
    
    def _extract_option(self, text, num_options):
        """
        ä»ç”Ÿæˆçš„æ–‡æœ¬ä¸­æå–é€‰é¡¹å­—æ¯ï¼ˆA/B/C/Dï¼‰
        
        Args:
            text: ç”Ÿæˆçš„æ–‡æœ¬
            num_options: é€‰é¡¹æ•°é‡
        
        Returns:
            option: æå–çš„é€‰é¡¹å­—æ¯ï¼ˆA/B/C/Dï¼‰ï¼Œå¦‚æœæå–å¤±è´¥è¿”å› "A"
        """
        # æ¸…ç†æ–‡æœ¬
        text = text.strip().upper()
        
        # å°è¯•å¤šç§æå–æ¨¡å¼
        patterns = [
            r'^([A-D])[.\s]',  # "A. " æˆ– "A "
            r'^([A-D])$',       # å•ç‹¬çš„ "A"
            r'ANSWER[:\s]*([A-D])',  # "ANSWER: A" æˆ– "ANSWER A"
            r'OPTION[:\s]*([A-D])',  # "OPTION: A"
            r'\(([A-D])\)',     # "(A)"
            r'([A-D])[.\s]',    # æ–‡æœ¬ä¸­çš„ "A. "
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text)
            if match:
                option = match.group(1)
                # éªŒè¯é€‰é¡¹åœ¨æœ‰æ•ˆèŒƒå›´å†…
                option_idx = ord(option) - ord('A')
                if 0 <= option_idx < num_options:
                    return option
        
        # å¦‚æœæ‰€æœ‰æ¨¡å¼éƒ½å¤±è´¥ï¼ŒæŸ¥æ‰¾ç¬¬ä¸€ä¸ªå‡ºç°çš„ A/B/C/D
        valid_options = [chr(65 + i) for i in range(num_options)]
        for char in text:
            if char in valid_options:
                return char
        
        # é»˜è®¤è¿”å› Aï¼ˆé¿å…é”™è¯¯ï¼‰
        print(f"âš ï¸  Warning: Could not extract option from: {text[:50]}..., defaulting to 'A'")
        return "A"


if __name__ == "__main__":
    # ç®€å•æµ‹è¯•
    print("=" * 80)
    print("Testing LLaVA-NeXT-34B Wrapper")
    print("=" * 80)
    
    # åˆ›å»ºæµ‹è¯•å¸§
    test_frames = []
    for i in range(8):
        color = (255, 0, 0) if i < 4 else (0, 0, 255)
        img = Image.new('RGB', (336, 336), color=color)
        test_frames.append(img)
    
    # åŠ è½½æ¨¡å‹
    wrapper = LLaVANext34BWrapper()
    
    # æµ‹è¯•ç”Ÿæˆ
    question = "What colors appear in this video?"
    options = ["Red only", "Blue only", "Red and Blue", "Green and Yellow"]
    
    print(f"\nğŸ“ Question: {question}")
    print(f"ğŸ“‹ Options: {options}")
    print(f"ğŸ¬ Frames: {len(test_frames)}")
    print("\nğŸ”® Generating...")
    
    answer = wrapper.generate(test_frames, question, options)
    
    print(f"\nâœ… Answer: {answer}")
    print("=" * 80)
