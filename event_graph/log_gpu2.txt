`torch_dtype` is deprecated! Use `dtype` instead!
ğŸš€ Process 2/4 starting on cuda
ğŸ“‚ Loading Dataset: VRBench
ğŸ”„ [VRBench] è·¯å¾„ä¿®æ­£: è‡ªåŠ¨è¿›å…¥å­ç›®å½• /root/icml2026/dataset/VRBench
ğŸ“‚ [VRBench] æ•°æ®é›†æ ¹ç›®å½•: /root/icml2026/dataset/VRBench
ğŸ“„ åŠ è½½å…ƒæ•°æ®: VRBench_eval.jsonl
ğŸ” æ‰«ææœ¬åœ°å·²è§£å‹çš„è§†é¢‘æ–‡ä»¶...
   ç¡¬ç›˜ä¸Šå®é™…æ‰¾åˆ° 8 ä¸ªè§†é¢‘ã€‚
âœ… æ•°æ®é›†æ„å»ºå®Œæˆï¼
   - è·³è¿‡ç¼ºå¤±è§†é¢‘çš„æ¡ç›®: 952
   - æœ‰æ•ˆæµ‹è¯•æ ·æœ¬æ•°: 70 (ä»…åŒ…å«æœ¬åœ°å­˜åœ¨çš„è§†é¢‘)
âš ï¸ DEBUG MODE: Truncated to first 100 samples.
ğŸ”„ Chunk 2: Processing samples 36 to 54 (Count: 18)
Loading Qwen2.5-VL from Qwen/Qwen2.5-VL-7B-Instruct...
Loading checkpoint shards:   0%|                                                                                                                                                                                                                                                    | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                                                                                            | 1/5 [00:02<00:10,  2.62s/it]Loading checkpoint shards:  40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                                                                                                             | 2/5 [00:04<00:07,  2.38s/it]Loading checkpoint shards:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                                                                              | 3/5 [00:07<00:04,  2.34s/it]Loading checkpoint shards:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                               | 4/5 [00:09<00:02,  2.30s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.68s/it]Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:09<00:00,  1.99s/it]
The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.
Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.
/usr/local/lib/python3.10/dist-packages/transnetv2_pytorch/transnetv2_pytorch.py:120: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  state_dict = torch.load(model_path, map_location='cpu')  # Load to CPU first
Qwen2.5-VL loaded successfully.
ğŸš€ [EventGraph] Initializing TransNet V2 Detector...
[TransNet V2] Loading pretrained model...
  âœ“ TransNet V2 loaded on cuda
ğŸš€ Start processing 18 samples...
GPU 2:   0%|                                                                                                                                                                                                                                                                       | 0/18 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:603: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:185.)
  return F.conv3d(
/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:117: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:185.)
  return F.linear(input, self.weight, self.bias)
/usr/local/lib/python3.10/dist-packages/transnetv2_pytorch/transnetv2_pytorch.py:706: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:185.)
  similarities = torch.bmm(x, x.transpose(1, 2))  # [batch_size, time_window, time_window]
/usr/local/lib/python3.10/dist-packages/transnetv2_pytorch/transnetv2_pytorch.py:760: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:185.)
  similarities = torch.bmm(x, x.transpose(1, 2))  # [batch_size, time_window, time_window]
[TransNet V2] Detecting shots in: 0wEsr-o4yHo.mp4
  Video info: 263215 frames, 30.00 fps
  Processing video in chunks of 500 frames...
    Processed 1000/263215 frames
    Processed 2000/263215 frames
    Processed 3000/263215 frames
    Processed 4000/263215 frames
    Processed 5000/263215 frames
    Processed 6000/263215 frames
    Processed 7000/263215 frames
    Processed 8000/263215 frames
    Processed 9000/263215 frames
    Processed 10000/263215 frames
    Processed 11000/263215 frames
    Processed 12000/263215 frames
    Processed 13000/263215 frames
    Processed 14000/263215 frames
    Processed 15000/263215 frames
    Processed 16000/263215 frames
    Processed 17000/263215 frames
    Processed 18000/263215 frames
    Processed 19000/263215 frames
    Processed 20000/263215 frames
    Processed 21000/263215 frames
    Processed 22000/263215 frames
    Processed 23000/263215 frames
    Processed 24000/263215 frames
    Processed 25000/263215 frames
    Processed 26000/263215 frames
    Processed 27000/263215 frames
    Processed 28000/263215 frames
    Processed 29000/263215 frames
    Processed 30000/263215 frames
    Processed 31000/263215 frames
    Processed 32000/263215 frames
    Processed 33000/263215 frames
    Processed 34000/263215 frames
    Processed 35000/263215 frames
    Processed 36000/263215 frames
    Processed 37000/263215 frames
    Processed 38000/263215 frames
    Processed 39000/263215 frames
    Processed 40000/263215 frames
    Processed 41000/263215 frames
    Processed 42000/263215 frames
    Processed 43000/263215 frames
    Processed 44000/263215 frames
    Processed 45000/263215 frames
    Processed 46000/263215 frames
    Processed 47000/263215 frames
    Processed 48000/263215 frames
    Processed 49000/263215 frames
    Processed 50000/263215 frames
    Processed 51000/263215 frames
    Processed 52000/263215 frames
    Processed 53000/263215 frames
    Processed 54000/263215 frames
    Processed 55000/263215 frames
    Processed 56000/263215 frames
    Processed 57000/263215 frames
    Processed 58000/263215 frames
    Processed 59000/263215 frames
    Processed 60000/263215 frames
    Processed 61000/263215 frames
    Processed 62000/263215 frames
    Processed 63000/263215 frames
    Processed 64000/263215 frames
    Processed 65000/263215 frames
    Processed 66000/263215 frames
    Processed 67000/263215 frames
    Processed 68000/263215 frames
    Processed 69000/263215 frames
    Processed 70000/263215 frames
    Processed 71000/263215 frames
    Processed 72000/263215 frames
    Processed 73000/263215 frames
    Processed 74000/263215 frames
    Processed 75000/263215 frames
    Processed 76000/263215 frames
    Processed 77000/263215 frames
    Processed 78000/263215 frames
    Processed 79000/263215 frames
    Processed 80000/263215 frames
    Processed 81000/263215 frames
    Processed 82000/263215 frames
    Processed 83000/263215 frames
    Processed 84000/263215 frames
    Processed 85000/263215 frames
    Processed 86000/263215 frames
    Processed 87000/263215 frames
    Processed 88000/263215 frames
    Processed 89000/263215 frames
    Processed 90000/263215 frames
    Processed 91000/263215 frames
    Processed 92000/263215 frames
    Processed 93000/263215 frames
    Processed 94000/263215 frames
    Processed 95000/263215 frames
    Processed 96000/263215 frames
    Processed 97000/263215 frames
    Processed 98000/263215 frames
    Processed 99000/263215 frames
    Processed 100000/263215 frames
    Processed 101000/263215 frames
    Processed 102000/263215 frames
    Processed 103000/263215 frames
    Processed 104000/263215 frames
    Processed 105000/263215 frames
    Processed 106000/263215 frames
    Processed 107000/263215 frames
    Processed 108000/263215 frames
    Processed 109000/263215 frames
    Processed 110000/263215 frames
    Processed 111000/263215 frames
    Processed 112000/263215 frames
    Processed 113000/263215 frames
    Processed 114000/263215 frames
    Processed 115000/263215 frames
    Processed 116000/263215 frames
    Processed 117000/263215 frames
    Processed 118000/263215 frames
    Processed 119000/263215 frames
    Processed 120000/263215 frames
    Processed 121000/263215 frames
    Processed 122000/263215 frames
    Processed 123000/263215 frames
    Processed 124000/263215 frames
    Processed 125000/263215 frames
    Processed 126000/263215 frames
    Processed 127000/263215 frames
    Processed 128000/263215 frames
    Processed 129000/263215 frames
    Processed 130000/263215 frames
    Processed 131000/263215 frames
    Processed 132000/263215 frames
    Processed 133000/263215 frames
    Processed 134000/263215 frames
    Processed 135000/263215 frames
    Processed 136000/263215 frames
    Processed 137000/263215 frames
    Processed 138000/263215 frames
    Processed 139000/263215 frames
    Processed 140000/263215 frames
    Processed 141000/263215 frames
    Processed 142000/263215 frames
    Processed 143000/263215 frames
    Processed 144000/263215 frames
    Processed 145000/263215 frames
    Processed 146000/263215 frames
    Processed 147000/263215 frames
    Processed 148000/263215 frames
    Processed 149000/263215 frames
    Processed 150000/263215 frames
    Processed 151000/263215 frames
    Processed 152000/263215 frames
    Processed 153000/263215 frames
    Processed 154000/263215 frames
    Processed 155000/263215 frames
    Processed 156000/263215 frames
    Processed 157000/263215 frames
    Processed 158000/263215 frames
    Processed 159000/263215 frames
    Processed 160000/263215 frames
    Processed 161000/263215 frames
    Processed 162000/263215 frames
    Processed 163000/263215 frames
    Processed 164000/263215 frames
    Processed 165000/263215 frames
    Processed 166000/263215 frames
    Processed 167000/263215 frames
    Processed 168000/263215 frames
    Processed 169000/263215 frames
    Processed 170000/263215 frames
    Processed 171000/263215 frames
    Processed 172000/263215 frames
    Processed 173000/263215 frames
    Processed 174000/263215 frames
    Processed 175000/263215 frames
    Processed 176000/263215 frames
    Processed 177000/263215 frames
    Processed 178000/263215 frames
    Processed 179000/263215 frames
    Processed 180000/263215 frames
    Processed 181000/263215 frames
    Processed 182000/263215 frames
    Processed 183000/263215 frames
    Processed 184000/263215 frames
    Processed 185000/263215 frames
    Processed 186000/263215 frames
    Processed 187000/263215 frames
    Processed 188000/263215 frames
    Processed 189000/263215 frames
    Processed 190000/263215 frames
    Processed 191000/263215 frames
    Processed 192000/263215 frames
    Processed 193000/263215 frames
    Processed 194000/263215 frames
    Processed 195000/263215 frames
    Processed 196000/263215 frames
    Processed 197000/263215 frames
    Processed 198000/263215 frames
    Processed 199000/263215 frames
    Processed 200000/263215 frames
    Processed 201000/263215 frames
    Processed 202000/263215 frames
    Processed 203000/263215 frames
    Processed 204000/263215 frames
    Processed 205000/263215 frames
    Processed 206000/263215 frames
    Processed 207000/263215 frames
    Processed 208000/263215 frames
    Processed 209000/263215 frames
    Processed 210000/263215 frames
    Processed 211000/263215 frames
    Processed 212000/263215 frames
    Processed 213000/263215 frames
    Processed 214000/263215 frames
    Processed 215000/263215 frames
    Processed 216000/263215 frames
    Processed 217000/263215 frames
    Processed 218000/263215 frames
    Processed 219000/263215 frames
    Processed 220000/263215 frames
    Processed 221000/263215 frames
    Processed 222000/263215 frames
    Processed 223000/263215 frames
    Processed 224000/263215 frames
    Processed 225000/263215 frames
    Processed 226000/263215 frames
    Processed 227000/263215 frames
    Processed 228000/263215 frames
    Processed 229000/263215 frames
    Processed 230000/263215 frames
    Processed 231000/263215 frames
    Processed 232000/263215 frames
    Processed 233000/263215 frames
/root/icml2026/event_graph/methods/graph_builder.py:21: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:185.)
  sim_global = torch.mm(g_norm, g_norm.t()) # (N, N)
/root/icml2026/event_graph/methods/graph_builder.py:48: UserWarning: Deterministic behavior was enabled with either `torch.use_deterministic_algorithms(True)` or `at::Context::setDeterministicAlgorithms(true)`, but this operation is not deterministic because it uses CuBLAS and you have CUDA >= 10.2. To enable deterministic behavior in this case, you must set an environment variable before running your PyTorch application: CUBLAS_WORKSPACE_CONFIG=:4096:8 or CUBLAS_WORKSPACE_CONFIG=:16:8. For more information, go to https://docs.nvidia.com/cuda/cublas/index.html#results-reproducibility (Triggered internally at ../aten/src/ATen/Context.cpp:185.)
  pair_sim = torch.matmul(q_chunk, tgt.transpose(1, 2))
