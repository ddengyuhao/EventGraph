# # /root/hhq/main_code/datasets/videomme.py
# import os
# import json
# import re
# from .base_dataset import BaseDataset

# class VideoMMEDataset(BaseDataset):
#     def __init__(self, root_dir, duration_mode="all"):
#         super().__init__(root_dir)
        
#         self.json_path = os.path.join(root_dir, "Video-MME", "video_mme.json")
#         self.video_root = os.path.join(root_dir, "Video-MME", "videos") 
        
#         print(f"[VideoMME] Loading json from {self.json_path}...")
#         with open(self.json_path, 'r', encoding='utf-8') as f:
#             data = json.load(f)
            
#         # 1. å»ºç«‹è§†é¢‘ç´¢å¼• (è¿™æ­¥å¿…é¡»ä¿ç•™ï¼Œå¦åˆ™æ‰¾ä¸åˆ°æ–‡ä»¶)
#         self.video_map = self._build_video_index(self.video_root)
        
#         self.samples = []
#         video_count = 0
        
#         print("ğŸš€ [VideoMME] FORCE LOAD MODE: Loading EVERYTHING found on disk...")
        
#         for item in data:
#             # 2. æŸ¥æ‰¾è§†é¢‘è·¯å¾„
#             video_id = str(item.get('video_id', '')).strip()
#             url = item.get('url', '')
            
#             fpath = self.video_map.get(video_id)
#             if not fpath and url:
#                 yt_id = self._extract_youtube_id(url)
#                 if yt_id: fpath = self.video_map.get(yt_id)
#             if not fpath and video_id.startswith("_"):
#                 fpath = self.video_map.get(video_id[1:])

#             # å¦‚æœæ‰¾ä¸åˆ°æ–‡ä»¶ï¼Œç‰©ç†ä¸Šæ²¡æ³•è·‘ï¼Œè·³è¿‡
#             if not fpath: 
#                 continue
            
#             video_count += 1

#             # 3. æ„é€ æ ·æœ¬ (ä¸åšä»»ä½•ç­›é€‰)
#             # ç»™ä¸€ä¸ªé»˜è®¤æ—¶é•¿é˜²æ­¢é™¤é›¶æŠ¥é”™
#             dummy_duration = 3600 

#             for q in item['questions']:
#                 self.samples.append({
#                     "id": f"{video_id}_{q['question_id']}",
#                     "video_path": fpath,
#                     "duration": dummy_duration,
#                     "question": q['question'],
#                     "options": q['options'],
#                     "answer": q['answer'],
#                     "task_type": q['task_type']
#                 })
        
#         print(f"âœ… Successfully loaded {len(self.samples)} samples from {video_count} videos.")

#         # === å†’çƒŸæµ‹è¯•å¼ºåˆ¶æˆªæ–­å·²ç¦ç”¨ ===
#         # ç°åœ¨ç”± run_inference.py çš„ --max_samples å‚æ•°æ§åˆ¶æ ·æœ¬æ•°
#         # ============================

#     def _build_video_index(self, root_dir):
#         print(f"    -> Indexing videos in {root_dir}...")
#         idx = {}
#         for root, _, files in os.walk(root_dir):
#             for file in files:
#                 if file.lower().endswith(('.mp4', '.mkv', '.webm', '.avi')):
#                     name = os.path.splitext(file)[0]
#                     full_path = os.path.join(root, file)
#                     idx[name] = full_path
#                     if name.startswith("_"):
#                         idx[name[1:]] = full_path
#         print(f"    -> Indexed {len(idx)} files.")
#         return idx

#     def _extract_youtube_id(self, url):
#         if not isinstance(url, str): return None
#         patterns = [r"v=([a-zA-Z0-9_-]{11})", r"youtu\.be/([a-zA-Z0-9_-]{11})"]
#         for p in patterns:
#             match = re.search(p, url)
#             if match: return match.group(1)
#         return None

import os
import glob
import pandas as pd
from torch.utils.data import Dataset

class VideoMMEDataset(Dataset):
    def __init__(self, root_dir="/root/icml2026/dataset/Video-MME/videomme", split="test"):
        self.root_dir = root_dir
        # 1. æ™ºèƒ½è·¯å¾„æ¢æµ‹
        potential_subdirs = ["Video-MME", "videomme", ".cache"]
        for sub in potential_subdirs:
            sub_path = os.path.join(self.root_dir, sub)
            if os.path.exists(sub_path):
                self.root_dir = sub_path
        
        print(f"ğŸ“‚ [Video-MME] æ•°æ®é›†æ ¹ç›®å½•: {self.root_dir}")

        # 2. åŠ è½½å…ƒæ•°æ® (.parquet)
        parquet_files = glob.glob(os.path.join(self.root_dir, "**", "*.parquet"), recursive=True)
        if not parquet_files:
            parquet_files = glob.glob(os.path.join(os.path.dirname(self.root_dir), "**", "*.parquet"), recursive=True)
            
        if not parquet_files:
            raise FileNotFoundError(f"âŒ æœªæ‰¾åˆ° .parquet æ–‡ä»¶ï¼æœç´¢èŒƒå›´: {self.root_dir}")
        
        parquet_path = parquet_files[0]
        print(f"ğŸ“„ åŠ è½½å…ƒæ•°æ®: {os.path.basename(parquet_path)}")

        try:
            df = pd.read_parquet(parquet_path)
        except Exception as e:
            print(f"âŒ Parquet è¯»å–å¤±è´¥: {e}")
            return

        print(f"   å…ƒæ•°æ®åŒ…å« {len(df)} æ¡è®°å½•ã€‚")
        
        # 3. æ‰«æè§†é¢‘æ–‡ä»¶
        search_roots = [
            self.root_dir, 
            os.path.join(self.root_dir, "videos"),
            os.path.dirname(parquet_path)
        ]
        
        video_map = {}
        all_videos = []
        for search_root in set(search_roots):
            if os.path.exists(search_root):
                found = sorted(glob.glob(os.path.join(search_root, "**", "*.mp4"), recursive=True)) + \
                        sorted(glob.glob(os.path.join(search_root, "**", "*.mkv"), recursive=True))
                all_videos.extend(found)
        
        all_videos = list(set(all_videos)) # å»é‡

        for v_path in all_videos:
            fname = os.path.basename(v_path)       # "1uqupftxFOM.mp4"
            fid = os.path.splitext(fname)[0]       # "1uqupftxFOM"
            video_map[fname] = v_path
            video_map[fid] = v_path
            
        print(f"ğŸ” ç¡¬ç›˜ä¸Šå®é™…æ‰¾åˆ° {len(all_videos)} ä¸ªè§†é¢‘æ–‡ä»¶ã€‚")

        # 4. æ„å»ºæ ·æœ¬ (æ ¸å¿ƒä¿®å¤: URL ID æå–)
        self.samples = []
        skipped_count = 0
        
        def extract_youtube_id(url):
            if not isinstance(url, str): return None
            # å¤„ç†æ ‡å‡†æ ¼å¼ https://www.youtube.com/watch?v=ID
            if "v=" in url:
                return url.split("v=")[1].split("&")[0]
            # å¤„ç†çŸ­é“¾ https://youtu.be/ID
            elif "youtu.be/" in url:
                return url.split("youtu.be/")[1].split("?")[0]
            return None

        for index, row in df.iterrows():
            # ç­–ç•¥1: ä» URL æå– (æœ€å¯é )
            candidates = []
            if 'url' in row:
                yt_id = extract_youtube_id(row['url'])
                if yt_id: candidates.append(yt_id)
            
            # ç­–ç•¥2: å°è¯• videoID åˆ— (æœ‰äº›æ•°æ®é›†è¿™ä¸ªåˆ—å­˜çš„æ˜¯çœŸå®ID)
            if 'videoID' in row:
                candidates.append(str(row['videoID']).strip())
                
            # ç­–ç•¥3: åŸå§‹ video_id (è™½ç„¶çœ‹èµ·æ¥æ˜¯åºå· '001'ï¼Œä½†ä¹Ÿè¯•ä¸€ä¸‹)
            candidates.append(str(row['video_id']).strip())
            
            # é€ä¸ªå°è¯•åŒ¹é…
            video_path = None
            for key in candidates:
                if key in video_map:
                    video_path = video_map[key]
                    break
                elif f"{key}.mp4" in video_map:
                    video_path = video_map[f"{key}.mp4"]
                    break
            
            if video_path is None:
                skipped_count += 1
                continue

            options = row['options']
            if hasattr(options, 'tolist'):
                options = options.tolist()
            
            self.samples.append({
                "id": f"vmme_{candidates[0]}_{index}", # ä½¿ç”¨æ‰¾åˆ°çš„ç¬¬ä¸€ä¸ªIDä½œä¸ºkey
                "video_path": video_path,
                "question": row['question'],
                "options": options,
                "answer": row['answer']
            })

        print(f"âœ… æ•°æ®é›†æ„å»ºå®Œæˆï¼")
        print(f"   - è·³è¿‡ç¼ºå¤±è§†é¢‘: {skipped_count}")
        print(f"   - æœ‰æ•ˆæ ·æœ¬æ•°: {len(self.samples)}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        return self.samples[idx]

# import os
# import glob
# import pandas as pd
# from torch.utils.data import Dataset

# class VideoMMEDataset(Dataset):
#     def __init__(self, root_dir="/root/icml2026/dataset/Video-MME/videomme", split="test"):
#         # === 1. æ™ºèƒ½è·¯å¾„æ¢æµ‹ ===
#         # å³ä½¿ä¼ å…¥çš„æ˜¯é€šç”¨çš„ dataset æ ¹ç›®å½•ï¼Œä¹Ÿèƒ½è‡ªåŠ¨æ‰¾åˆ° Video-MME
#         self.root_dir = root_dir
#         print(f"ğŸ“‚ [Video-MME] åˆå§‹åŒ–ï¼Œæœç´¢æ ¹ç›®å½•: {self.root_dir}")

#         # ä¼˜å…ˆæ£€æŸ¥å¸¸è§çš„å­ç›®å½•åï¼Œç¼©å°æœç´¢èŒƒå›´
#         potential_subdirs = ["Video-MME", "videomme", ".cache"]
#         for sub in potential_subdirs:
#             sub_path = os.path.join(self.root_dir, sub)
#             if os.path.exists(sub_path):
#                 self.root_dir = sub_path
#                 print(f"   -> è‡ªåŠ¨è¿›å…¥å­ç›®å½•: {self.root_dir}")

#         # === 2. æ·±åº¦æœç´¢å…ƒæ•°æ® (.parquet) ===
#         # ä½¿ç”¨ recursive=True ç©¿é€æ‰€æœ‰å­æ–‡ä»¶å¤¹ (.cache, videomme ç­‰)
#         print("ğŸ” æ­£åœ¨æ·±åº¦æœç´¢ .parquet å…ƒæ•°æ®æ–‡ä»¶...")
#         parquet_files = glob.glob(os.path.join(self.root_dir, "**", "*.parquet"), recursive=True)
        
#         if not parquet_files:
#             # å¦‚æœæ²¡æ‰¾åˆ°ï¼Œå°è¯•å›é€€åˆ°ä¸Šä¸€çº§å†æœä¸€æ¬¡ï¼ˆé˜²å¾¡æ€§ç¼–ç¨‹ï¼‰
#             parent_dir = os.path.dirname(self.root_dir)
#             parquet_files = glob.glob(os.path.join(parent_dir, "**", "*.parquet"), recursive=True)

#         if not parquet_files:
#             print(f"âŒ é”™è¯¯: æœªæ‰¾åˆ° .parquet æ–‡ä»¶ã€‚")
#             print(f"   æœç´¢è·¯å¾„åŒ…æ‹¬: {self.root_dir} åŠå…¶æ‰€æœ‰å­ç›®å½•")
#             raise FileNotFoundError("æ— æ³•æ‰¾åˆ° Video-MME çš„å…ƒæ•°æ®æ–‡ä»¶")
        
#         # é€šå¸¸åªæœ‰ä¸€ä¸ª parquetï¼Œå–ç¬¬ä¸€ä¸ª
#         parquet_path = parquet_files[0]
#         print(f"ğŸ“„ é”å®šå…ƒæ•°æ®: {parquet_path}")

#         try:
#             df = pd.read_parquet(parquet_path)
#         except Exception as e:
#             print(f"âŒ Parquet è¯»å–å¤±è´¥ (éœ€è¦ pip install pandas pyarrow): {e}")
#             return

#         print(f"   å…ƒæ•°æ®åŒ…å« {len(df)} æ¡è®°å½•ã€‚")

#         # === 3. æ·±åº¦æœç´¢è§†é¢‘æ–‡ä»¶ ===
#         # æ ¹æ®æˆªå›¾ï¼Œè§†é¢‘å¯èƒ½åœ¨ videos/data/ ä¸‹ï¼Œæ‰€ä»¥å¿…é¡»é€’å½’æœç´¢
#         print(f"ğŸ” æ­£åœ¨æ·±åº¦æœç´¢è§†é¢‘æ–‡ä»¶ (.mp4/.mkv)...")
#         # è¿™é‡Œçš„ root_dir å·²ç»è¢«æ›´æ–°ä¸ºåŒ…å« parquet çš„ç›®å½•ï¼Œé€šå¸¸è§†é¢‘ä¹Ÿåœ¨é™„è¿‘
#         search_roots = [
#             self.root_dir, 
#             os.path.join(self.root_dir, "videos"),
#             os.path.dirname(parquet_path) # parquet æ‰€åœ¨ç›®å½•
#         ]
        
#         video_map = {}
#         all_videos = []
        
#         for search_root in set(search_roots): # å»é‡
#             if os.path.exists(search_root):
#                 found = sorted(glob.glob(os.path.join(search_root, "**", "*.mp4"), recursive=True)) + \
#                         sorted(glob.glob(os.path.join(search_root, "**", "*.mkv"), recursive=True))
#                 all_videos.extend(found)
        
#         # å»é‡ï¼ˆå› ä¸ºå¯èƒ½å¤šæ¬¡æœåˆ°åŒä¸€ä¸ªæ–‡ä»¶ï¼‰
#         all_videos = list(set(all_videos))

#         for v_path in all_videos:
#             fname = os.path.basename(v_path)
#             fid = os.path.splitext(fname)[0] 
#             video_map[fname] = v_path
#             video_map[fid] = v_path
            
#             # Video-MME ç‰¹ä¾‹å¤„ç†ï¼šæœ‰æ—¶å€™ ID ä¸åŒ…å«åç¼€ï¼Œä½†æ–‡ä»¶åä¹±ä¸ƒå…«ç³Ÿ
#             # å¦‚æœä½ çš„ ID æ˜¯ "0ag_Qi5OEd0"ï¼Œæ–‡ä»¶åä¹Ÿæ˜¯ "0ag_Qi5OEd0.mp4"ï¼Œä¸Šé¢çš„ fid å°±èƒ½åŒ¹é…

#         print(f"   ç¡¬ç›˜ä¸Šå®é™…æ‰¾åˆ° {len(all_videos)} ä¸ªè§†é¢‘æ–‡ä»¶ã€‚")
#         if len(all_videos) == 0:
#             print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°è§†é¢‘ï¼è¯·ç¡®è®¤å·²è§£å‹åˆ° {self.root_dir} ä¸‹çš„æŸä¸ªå­ç›®å½•")

#         # === 4. æ„å»ºæ ·æœ¬ ===
#         self.samples = []
#         skipped_count = 0
        
#         for index, row in df.iterrows():
#             vid_id = str(row['video_id'])
            
#             # åŒ¹é…é€»è¾‘
#             video_path = None
#             if vid_id in video_map:
#                 video_path = video_map[vid_id]
#             elif f"{vid_id}.mp4" in video_map:
#                 video_path = video_map[f"{vid_id}.mp4"]
            
#             # å¦‚æœæ²¡æ‰¾åˆ°è§†é¢‘ï¼ˆå› ä¸ºå¯èƒ½åªè§£å‹äº†ä¸€éƒ¨åˆ†ï¼‰ï¼Œè·³è¿‡
#             if video_path is None:
#                 skipped_count += 1
#                 continue

#             options = row['options']
#             if hasattr(options, 'tolist'):
#                 options = options.tolist()
            
#             self.samples.append({
#                 "id": f"vmme_{vid_id}_{index}",
#                 "video_path": video_path,
#                 "question": row['question'],
#                 "options": options,
#                 "answer": row['answer']
#             })

#         print(f"âœ… æ•°æ®é›†æ„å»ºå®Œæˆï¼")
#         print(f"   - è·³è¿‡ç¼ºå¤±è§†é¢‘: {skipped_count}")
#         print(f"   - æœ‰æ•ˆæ ·æœ¬æ•°: {len(self.samples)}")

#     def __len__(self):
#         return len(self.samples)

#     def __getitem__(self, idx):
#         return self.samples[idx]